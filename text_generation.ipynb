{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:08.261025Z",
     "iopub.status.busy": "2022-05-03T11:14:08.260828Z",
     "iopub.status.idle": "2022-05-03T11:14:10.284556Z",
     "shell.execute_reply": "2022-05-03T11:14:10.283846Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.288588Z",
     "iopub.status.busy": "2022-05-03T11:14:10.288339Z",
     "iopub.status.idle": "2022-05-03T11:14:10.512538Z",
     "shell.execute_reply": "2022-05-03T11:14:10.511842Z"
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.515842Z",
     "iopub.status.busy": "2022-05-03T11:14:10.515602Z",
     "iopub.status.idle": "2022-05-03T11:14:10.521336Z",
     "shell.execute_reply": "2022-05-03T11:14:10.520758Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 13810631 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.530172Z",
     "iopub.status.busy": "2022-05-03T11:14:10.529967Z",
     "iopub.status.idle": "2022-05-03T11:14:10.544918Z",
     "shell.execute_reply": "2022-05-03T11:14:10.544310Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.547650Z",
     "iopub.status.busy": "2022-05-03T11:14:10.547458Z",
     "iopub.status.idle": "2022-05-03T11:14:12.216225Z",
     "shell.execute_reply": "2022-05-03T11:14:12.215486Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.219925Z",
     "iopub.status.busy": "2022-05-03T11:14:12.219236Z",
     "iopub.status.idle": "2022-05-03T11:14:12.230858Z",
     "shell.execute_reply": "2022-05-03T11:14:12.230260Z"
    },
    "id": "6GMlCe3qzaL9"
   },
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.234414Z",
     "iopub.status.busy": "2022-05-03T11:14:12.233898Z",
     "iopub.status.idle": "2022-05-03T11:14:12.241111Z",
     "shell.execute_reply": "2022-05-03T11:14:12.240543Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[61, 62, 63, 64, 65, 66, 67], [84, 85, 86]]>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.244473Z",
     "iopub.status.busy": "2022-05-03T11:14:12.244010Z",
     "iopub.status.idle": "2022-05-03T11:14:12.251817Z",
     "shell.execute_reply": "2022-05-03T11:14:12.251224Z"
    },
    "id": "Wd2m3mqkDjRj"
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.255016Z",
     "iopub.status.busy": "2022-05-03T11:14:12.254548Z",
     "iopub.status.idle": "2022-05-03T11:14:12.259845Z",
     "shell.execute_reply": "2022-05-03T11:14:12.259298Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.263027Z",
     "iopub.status.busy": "2022-05-03T11:14:12.262587Z",
     "iopub.status.idle": "2022-05-03T11:14:12.273779Z",
     "shell.execute_reply": "2022-05-03T11:14:12.273214Z"
    },
    "id": "zxYI-PeltqKP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.276992Z",
     "iopub.status.busy": "2022-05-03T11:14:12.276505Z",
     "iopub.status.idle": "2022-05-03T11:14:12.280017Z",
     "shell.execute_reply": "2022-05-03T11:14:12.279421Z"
    },
    "id": "w5apvBDn9Ind"
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.283397Z",
     "iopub.status.busy": "2022-05-03T11:14:12.282940Z",
     "iopub.status.idle": "2022-05-03T11:14:12.693441Z",
     "shell.execute_reply": "2022-05-03T11:14:12.692846Z"
    },
    "id": "UopbsKi88tm5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(13810631,), dtype=int64, numpy=array([51, 68, 69, ..., 65,  2,  1], dtype=int64)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.696712Z",
     "iopub.status.busy": "2022-05-03T11:14:12.696216Z",
     "iopub.status.idle": "2022-05-03T11:14:12.700189Z",
     "shell.execute_reply": "2022-05-03T11:14:12.699616Z"
    },
    "id": "qmxrYDCTy-eL"
   },
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.724378Z",
     "iopub.status.busy": "2022-05-03T11:14:12.723876Z",
     "iopub.status.idle": "2022-05-03T11:14:12.726907Z",
     "shell.execute_reply": "2022-05-03T11:14:12.726324Z"
    },
    "id": "C-G2oaTxy6km"
   },
   "outputs": [],
   "source": [
    "seq_length = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.729823Z",
     "iopub.status.busy": "2022-05-03T11:14:12.729461Z",
     "iopub.status.idle": "2022-05-03T11:14:12.740383Z",
     "shell.execute_reply": "2022-05-03T11:14:12.739819Z"
    },
    "id": "BpdjRO2CzOfZ"
   },
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.757751Z",
     "iopub.status.busy": "2022-05-03T11:14:12.757363Z",
     "iopub.status.idle": "2022-05-03T11:14:12.760852Z",
     "shell.execute_reply": "2022-05-03T11:14:12.760178Z"
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.770840Z",
     "iopub.status.busy": "2022-05-03T11:14:12.770439Z",
     "iopub.status.idle": "2022-05-03T11:14:12.816930Z",
     "shell.execute_reply": "2022-05-03T11:14:12.816374Z"
    },
    "id": "B9iKPXkw5xwa"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.845656Z",
     "iopub.status.busy": "2022-05-03T11:14:12.845278Z",
     "iopub.status.idle": "2022-05-03T11:14:12.852723Z",
     "shell.execute_reply": "2022-05-03T11:14:12.852173Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 1000), dtype=tf.int64, name=None), TensorSpec(shape=(64, 1000), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.856129Z",
     "iopub.status.busy": "2022-05-03T11:14:12.855554Z",
     "iopub.status.idle": "2022-05-03T11:14:12.860086Z",
     "shell.execute_reply": "2022-05-03T11:14:12.859494Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.862758Z",
     "iopub.status.busy": "2022-05-03T11:14:12.862561Z",
     "iopub.status.idle": "2022-05-03T11:14:12.868444Z",
     "shell.execute_reply": "2022-05-03T11:14:12.867942Z"
    },
    "id": "wj8HQ2w8z4iO"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.871482Z",
     "iopub.status.busy": "2022-05-03T11:14:12.870964Z",
     "iopub.status.idle": "2022-05-03T11:14:12.884188Z",
     "shell.execute_reply": "2022-05-03T11:14:12.883662Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:12.887337Z",
     "iopub.status.busy": "2022-05-03T11:14:12.887142Z",
     "iopub.status.idle": "2022-05-03T11:14:19.110856Z",
     "shell.execute_reply": "2022-05-03T11:14:19.110010Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000, 103) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.114557Z",
     "iopub.status.busy": "2022-05-03T11:14:19.114071Z",
     "iopub.status.idle": "2022-05-03T11:14:19.127462Z",
     "shell.execute_reply": "2022-05-03T11:14:19.126830Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     multiple                  26368     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  105575    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,070,247\n",
      "Trainable params: 4,070,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "To get actual predictions from the model you need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
    "\n",
    "Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
    "\n",
    "Try it for the first example in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.135987Z",
     "iopub.status.busy": "2022-05-03T11:14:19.135473Z",
     "iopub.status.idle": "2022-05-03T11:14:19.140304Z",
     "shell.execute_reply": "2022-05-03T11:14:19.139623Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "This gives us, at each timestep, a prediction of the next character index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.143371Z",
     "iopub.status.busy": "2022-05-03T11:14:19.143038Z",
     "iopub.status.idle": "2022-05-03T11:14:19.148215Z",
     "shell.execute_reply": "2022-05-03T11:14:19.147418Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67,  56,  48,  25, 100,  99,  78,  93,  18,  72,  99,  18,  50,\n",
       "        98,  71,  16,  66,  69,  44,  84,  86,  53,  69,  78,  13,  34,\n",
       "        15,  61,  91,  39,  45,  52,  93,  38,  13,  67,  83,  59,  24,\n",
       "         5,  39,   3,  79,   7,  54,  87,   4,  14,  23,  86,   6,  28,\n",
       "        19,  26,  95,   4,  62,   7,  14,   9,   1,   2,  23,  82,  40,\n",
       "        46,  27,  65,  43,  55,  65,  58,  14,  99,  39,  87,  46,  60,\n",
       "        65,  60,  99,  94,  87,  13,  79,  51,  19,  85,  32,   0,  38,\n",
       "        81,  88,  39,  43,  67,  27,  64,  23,  48,  89,  20,  95,  25,\n",
       "        79,  12,  92,  93,  85,  75,  99,  78,  97,   5,  35,  49,  51,\n",
       "        69,  54, 100,   3,  18,  31,  95,  52,  38,  28,   9,  45,  11,\n",
       "        38,  47,  79,  25,   4,  45,  87,  22,  99,  71,  97,  39,  65,\n",
       "         7,  24,  91,  89,  99,  23,  92,  50,  39,  47,   7,  61,  41,\n",
       "         5,   2,  73,  91,  18,  37,  64,  96,  56,  85,  47,  49,  87,\n",
       "        47,  25,  55,  32,  55,  49,   1,  36,  75,  29,  22,  40,  48,\n",
       "        21,  63,   1,  27,  44,  76,  87,  74, 102,   8,  84,  28,  32,\n",
       "         8,  32,  99,  57,  80,  71,  27,  79,  56,  51,   6,  55,  12,\n",
       "        79,   1,  54,  62,   5,  32,  63,  62,  11,  20,  58,  95,  79,\n",
       "        73,  59,  50,  74,  83,  68,  65,   2,  92,  83,  38,  95,  60,\n",
       "        18,  21,   1,  24,   5,  48,  67,  36,  26,  88,  49,  90,  97,\n",
       "        84,  87,  94,  78,  47,  25,  54,  65,  78,  37,  42,  84,  40,\n",
       "        74,   8,  27,  93,  90,  57,  32,  68,  35,  32,  73,  51,  82,\n",
       "        69,  33,  45,   9,  88,  95,  24,   7,  24,  12,  57,  59,  53,\n",
       "        63,  24,  95,  52,  91,  27,  62,  53,  89,  62,  20,  94,  46,\n",
       "        23,  67, 102,  41,  43, 102,  12,  11,  19,  72,  31, 102,  43,\n",
       "        82,  60,  99,  29,  61,  65,  65,  39,  98,  79,  70,  58,  67,\n",
       "        28,  73,  41,  76,  42,  80,   4,   4,  74,  77,  60,  21,  15,\n",
       "        12, 102,  54,  68,  82,  87,  86,  90,  53,  47,  37,  15,  96,\n",
       "        11,  72,  67,  70,   1,  19,  28,  92,  77,   3,  28,  91,  77,\n",
       "        31,  76,   4,  93,  71,  41,  69,  73,   4,  59,  35,   1,   9,\n",
       "        26,  35,  97,  67,  29,  47,  20,  24,  76,  86,  94,  56,  64,\n",
       "        15,  58,  48,  53,  89,   4,  82,  19,  32,  45,  45,  31,  44,\n",
       "        60,  97,  79,  64,  60,  17,  95,  85,  66,  21,  92,  22,   8,\n",
       "        99,  69,  53,  76,  29,  30,  23,  27,  42, 101,  36,  66,  47,\n",
       "        91,  68,  20,  10,   4,  97,  65,  34,  81,  15,  98,  74,  46,\n",
       "        54,   3,  71,  59,  69,  89,  43,  78,  36,  18,  30,  87,  37,\n",
       "        45,  78,  14,  93,  42,  48,  63,   3,  49, 100,  34,  63,  99,\n",
       "        99,   0,  49,  10,  94,  52,  74, 102,   8,  13,  73,  78,  25,\n",
       "        13,  73,  71,   6,  86,  51,  54,  93,   1,  54,  57,  50,  42,\n",
       "        63,  31,  48,  95,  35,  47,  84,  45,  88,  52,  41,  92,  64,\n",
       "        90,  31,   4,  58,  24,  66,   7,  68,  76,  49,  12,  51,  63,\n",
       "        26,  72,  20,   6,  74,  95,   1,  25,  30,  75,  78,  29,  64,\n",
       "        57,  56,  91,  45,  50,   2,  91,  27,  50,  34,   5,   2,  95,\n",
       "        74,  57,  58,  62,  50,  97,   5,  24,  50,  36,   1,  73,  24,\n",
       "         1,  84,  83,  19,  76,   9,  26,  36,  95,  18,  73,  23,  72,\n",
       "        59,  66,  21,   1,  35,   2,  95,  81,  26,  29,  40,  14,  72,\n",
       "        52,   2,  21,  99,  24,   3,  54,  42,  89,  89,  44,  13,  82,\n",
       "        49,  25,  17,  67,   7,  43,   4,  41,  93,  19,  36,  67,  97,\n",
       "        17,  56,  32,  39,  75,  99,  36,  35,  44,  59,  85,  74,  76,\n",
       "        69,  43,  89,  71,  16,  18,  36,  59,  53,   9,  30,  15,  92,\n",
       "        57,  10,  61,  49,  73,  15,  77,  29,  25,  95,  49,  19,  87,\n",
       "        74,  66,  45,  86,  25,  92,  35,   0,  81,  25,  67,  36,  91,\n",
       "        80, 100,  62,  29,  52,  62,  19,  47,  41,  65,  87,   2,  83,\n",
       "        27,   2,  92,  30,  74,  28,  92,  16,  94, 101,  29,  22,  29,\n",
       "        69,  23,  82,  58,  96,  30,  50,  90,   8,  51,  45,  94,  14,\n",
       "        78,  91,  73,  73,  19,  29,   3,  16,  93,  80,  73,  40,   8,\n",
       "        35,  85,  38,  38,  22,   5,  48,  82,  95,  42,   3,  41,  86,\n",
       "        16,  40,  40,  11,  94,  15,  73,  97, 102,  18,  45,   8,  83,\n",
       "        61,  53,  15,  34,  12,  60,  69,  44,  59,  33,  98,  91,  14,\n",
       "        67,   1,   0,  48,  22,  81,  50,  53,  17,  18,  22,  90,  44,\n",
       "        76,  75,  59,  35,  20,  65,  22,   1,  90,  68,  68,  31,  45,\n",
       "        45,  86,  39,   8,  89,  55,  91,  43,  87,  83,  81,  68,  84,\n",
       "        83,  34,   3,  13,  28,  40,  22,  18,  80,  66,  57,  88,  43,\n",
       "        70,  93,  16,  63,  65,  95,  54,  52,  39,  54,  31,  84,  56,\n",
       "        65,  93,  27,  17,   7,  65,  66,  63,   7,  62,  75,  20,  62,\n",
       "         4,  19,  61,  64,  94,  92,  18,   3,  62,  72,   8,  27,  77,\n",
       "        77,   5,  53,  30,  77,  18,  11,  42,  14,  86,  85,  50,  31,\n",
       "        44,  55,  43,  89,   9,  99,   2,  34,  98,  57,  29,  32,  60,\n",
       "        66, 101, 101,  13,  41,  21,  29, 100,  48,  35,  79,  77,  95,\n",
       "        93,  50,  56,  39,  37,  60,  78,  91, 102,  51,   8,  65,  79,\n",
       "        95,  97,  14,  67,  55,  40,  13,  19,  46,  68,   6,  88,  68,\n",
       "        29,  50,  54,  48,  45,  86,   3,  88,  63,  61,  58,  77,  45,\n",
       "         0,  19,  61,  22,  65,  56,  63,  53,  32,   1,  74,  73,  89,\n",
       "        57,  43,  20, 101,  34,   7,   0,  53,   2,  58,   5,   1,  30,\n",
       "        61,   5,  79,  38,  69,  65,   9,  67,  98,  81,  12,  59,  91,\n",
       "         2,  39,  43,  85,  29,  37,  90,  36,  63,  25,  90, 100,  14,\n",
       "        75,  67,  71,  64,  68,   4,  22,  49,  29,  89,   3,   1,  52,\n",
       "        56,  13,  14,   0,  84,  69,  21,  40,  28,  87, 101,   8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "Decode these to see the text predicted by this untrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.151482Z",
     "iopub.status.busy": "2022-05-03T11:14:19.150968Z",
     "iopub.status.idle": "2022-05-03T11:14:19.157489Z",
     "shell.execute_reply": "2022-05-03T11:14:19.156834Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"ute lunch depending yet i go to the\\r\\nbathroom for four [\\xc2\\xa0__\\xc2\\xa0] minutes and\\r\\nall of a sudden you gotta know exactly\\r\\nwhere i'm at i don't get to leave for 15\\r\\nminutes if i go live for eight hours i\\r\\ndon't get to do a 30 minute lunch while\\r\\ni'm working my ass off\\r\\nputting my pedal to the goddamn metal\\r\\ngrinding churning out these dollar bills\\r\\nfor daddy bezos to make more money i\\r\\ncan't get five minutes in the bathroom\\r\\nwithout a [\\xc2\\xa0__\\xc2\\xa0] being like\\r\\nprobably jerking off\\r\\na fellow viewer in the chat room made a\\r\\nvalid point the point was that ludwig\\r\\nmay be taking long due to the high\\r\\nlevels of testosterone in his system\\r\\nwith that being said it was connecting\\r\\nthe dots from there\\r\\neverybody knows every time you jerk off\\r\\nyou lose your testosterone that's right\\r\\nif you guys don't know floyd mayweather\\r\\nis a virgin he has gotten a record zero\\r\\n[\\xc2\\xa0__\\xc2\\xa0] in a record 49 wins and zero\\r\\nlosses\\r\\nthose are correlated you need to connect\\r\\nthese dots it's 50. in my mind pacquiao\\r\\nfight doesn't count i\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'gYQ7\\xe2\\x82\\xac\\xc3\\xbbr\\xc3\\xa90l\\xc3\\xbb0S\\xc3\\xbak.fiMxzVir+C-a\\xc3\\xa3HNU\\xc3\\xa9G+gw]6\"H s$W|!,5z#:18\\xc3\\xae!b$,&\\n\\r5vIO9eLXe[,\\xc3\\xbbH|O_e_\\xc3\\xbb\\xc3\\xaa|+sT1yA[UNK]Gu\\xc2\\xa0HLg9d5Q\\xc3\\xa02\\xc3\\xae7s)\\xc3\\xa8\\xc3\\xa9yo\\xc3\\xbbr\\xc3\\xb6\"DRTiW\\xe2\\x82\\xac 0@\\xc3\\xaeUG:&N(GPs7!N|4\\xc3\\xbbk\\xc3\\xb6He$6\\xc3\\xa3\\xc3\\xa0\\xc3\\xbb5\\xc3\\xa8SHP$aJ\"\\rm\\xc3\\xa30Fd\\xc3\\xb3YyPR|P7XAXR\\nEo=4IQ3c\\n9Mp|n\\xe2\\x99\\xaa%x:A%A\\xc3\\xbbZtk9sYT#X)s\\nWb\"Acb(2[\\xc3\\xaesm]Snwhe\\r\\xc3\\xa8wG\\xc3\\xae_03\\n6\"QgE8\\xc2\\xa0R\\xc3\\xa2\\xc3\\xb6x|\\xc3\\xaarP7WerFKxIn%9\\xc3\\xa9\\xc3\\xa2ZAhDAmTviBN&\\xc2\\xa0\\xc3\\xae6$6)Z]Vc6\\xc3\\xaeU\\xc3\\xa39bV\\xc3\\xa0b2\\xc3\\xaaO5g\\xe2\\x99\\xaaJL\\xe2\\x99\\xaa)(1l@\\xe2\\x99\\xaaLv_\\xc3\\xbb=aeeH\\xc3\\xbasj[g:mJpKt!!nq_3-)\\xe2\\x99\\xaaWhv|z\\xc3\\xa2VPF-\\xc3\\xb3(lgj\\n1:\\xc3\\xa8q :\\xc3\\xa3q@p!\\xc3\\xa9kJim!]D\\n&8D\\xc3\\xb6g=P26pz\\xc3\\xaaYd-[QV\\xc3\\xa0!v1ANN@M_\\xc3\\xb6sd_/\\xc3\\xaeyf3\\xc3\\xa84%\\xc3\\xbbiVp=?59K\\xe2\\x84\\xa2EfP\\xc3\\xa3h2\\'!\\xc3\\xb6eCu-\\xc3\\xbanOW k]i\\xc3\\xa0LrE0?|FNr,\\xc3\\xa9KQc R\\xe2\\x82\\xacCc\\xc3\\xbb\\xc3\\xbb[UNK]R\\'\\xc3\\xaaUn\\xe2\\x99\\xaa%+mr7+mk#zTW\\xc3\\xa9\\nWZSKc@Q\\xc3\\xaeDPxN\\xc2\\xa0UJ\\xc3\\xa8d\\xc3\\xa2@![6f$hpR)Tc8l2#n\\xc3\\xae\\n7?or=dZY\\xc3\\xa3NS\\r\\xc3\\xa39SC\"\\r\\xc3\\xaenZ[bS\\xc3\\xb6\"6SE\\nm6\\nxw1p&8E\\xc3\\xae0m5l]f3\\nD\\r\\xc3\\xaeu8=I,lU\\r3\\xc3\\xbb6 WK\\xc3\\xa0\\xc3\\xa0M+vR7/g$L!J\\xc3\\xa91Eg\\xc3\\xb6/YAHo\\xc3\\xbbEDM]ynpiL\\xc3\\xa0k.0E]V&?-\\xc3\\xa8Z\\'aRm-q=7\\xc3\\xaeR1|nfNz7\\xc3\\xa8D[UNK]u7gE\\xc3\\xa3t\\xe2\\x82\\xacb=Ub1PJe|\\rw9\\r\\xc3\\xa8?n:\\xc3\\xa8.\\xc3\\xaa\\xe2\\x84\\xa2=4=i5v[\\xc3\\xb3?S\\xc3\\xa2%TN\\xc3\\xaa,r\\xc3\\xa3mm1= .\\xc3\\xa9tmI%DyGG4\"Qv\\xc3\\xaeK Jz.II(\\xc3\\xaa-m\\xc3\\xb6\\xe2\\x99\\xaa0N%waV-C)_iM]B\\xc3\\xba\\xc3\\xa3,g\\n[UNK]Q4uSV/04\\xc3\\xa2Mpo]D2e4\\n\\xc3\\xa2hh@NNzH%\\xc3\\xa0X\\xc3\\xa3L|wuhxwC +:I40tfZ\\xc2\\xa0Lj\\xc3\\xa9.ce\\xc3\\xaeWUHW@xYe\\xc3\\xa99/$efc$bo2b!1ad\\xc3\\xaa\\xc3\\xa80 bl%9qq\"V?q0(K,zyS@MXL\\xc3\\xa0&\\xc3\\xbb\\rC\\xc3\\xbaZ=A_f\\xe2\\x84\\xa2\\xe2\\x84\\xa2+J3=\\xe2\\x82\\xacQDsq\\xc3\\xae\\xc3\\xa9SYHF_r\\xc3\\xa3\\xe2\\x99\\xaaT%es\\xc3\\xae\\xc3\\xb6,gXI+1Oh#\\xc2\\xa0h=SWQNz \\xc2\\xa0ca[qN[UNK]1a4eYcVA\\nnm\\xc3\\xa0ZL2\\xe2\\x84\\xa2C$[UNK]V\\r[\"\\n?a\"sGie&g\\xc3\\xbau)]\\xc3\\xa3\\rHLy=F\\xc3\\xa2Ec7\\xc3\\xa2\\xe2\\x82\\xac,ogkdh!4R=\\xc3\\xa0 \\nUY+,[UNK]xi3I:|\\xe2\\x84\\xa2%'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### Attach an optimizer, and a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n",
    "\n",
    "Because your model returns logits, you need to set the `from_logits` flag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.160907Z",
     "iopub.status.busy": "2022-05-03T11:14:19.160460Z",
     "iopub.status.idle": "2022-05-03T11:14:19.163955Z",
     "shell.execute_reply": "2022-05-03T11:14:19.163262Z"
    },
    "id": "ZOeWdgxNFDXq"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.166953Z",
     "iopub.status.busy": "2022-05-03T11:14:19.166599Z",
     "iopub.status.idle": "2022-05-03T11:14:19.175314Z",
     "shell.execute_reply": "2022-05-03T11:14:19.174527Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 1000, 103)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.633491, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkvUIneTFiow"
   },
   "source": [
    "A newly initialized model shouldn't be too sure of itself, the output logits should all have similar magnitudes. To confirm this you can check that the exponential of the mean loss is approximately equal to the vocabulary size. A much higher loss means the model is sure of its wrong answers, and is badly initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.178576Z",
     "iopub.status.busy": "2022-05-03T11:14:19.178089Z",
     "iopub.status.idle": "2022-05-03T11:14:19.183572Z",
     "shell.execute_reply": "2022-05-03T11:14:19.182868Z"
    },
    "id": "MAJfS5YoFiHf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.87257"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.186765Z",
     "iopub.status.busy": "2022-05-03T11:14:19.186240Z",
     "iopub.status.idle": "2022-05-03T11:14:19.197413Z",
     "shell.execute_reply": "2022-05-03T11:14:19.196878Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6XBUUavgF56"
   },
   "source": [
    "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.200836Z",
     "iopub.status.busy": "2022-05-03T11:14:19.200416Z",
     "iopub.status.idle": "2022-05-03T11:14:19.204379Z",
     "shell.execute_reply": "2022-05-03T11:14:19.203646Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.207896Z",
     "iopub.status.busy": "2022-05-03T11:14:19.207296Z",
     "iopub.status.idle": "2022-05-03T11:14:19.210652Z",
     "shell.execute_reply": "2022-05-03T11:14:19.209961Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:19.214135Z",
     "iopub.status.busy": "2022-05-03T11:14:19.213597Z",
     "iopub.status.idle": "2022-05-03T11:16:14.167240Z",
     "shell.execute_reply": "2022-05-03T11:16:14.166580Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [],
   "source": [
    "# history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIdQ8c8NvMzV"
   },
   "source": [
    "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it.\n",
    "\n",
    "![To generate text the model's output is fed back to the input](images/text_generation_sampling.png)\n",
    "\n",
    "Each time you call the model you pass in some text and an internal state. The model returns a prediction for the next character and its new state. Pass the prediction and state back in to continue generating text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "The following makes a single step prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:14.171458Z",
     "iopub.status.busy": "2022-05-03T11:16:14.170910Z",
     "iopub.status.idle": "2022-05-03T11:16:14.180188Z",
     "shell.execute_reply": "2022-05-03T11:16:14.179593Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:14.183384Z",
     "iopub.status.busy": "2022-05-03T11:16:14.182965Z",
     "iopub.status.idle": "2022-05-03T11:16:14.193938Z",
     "shell.execute_reply": "2022-05-03T11:16:14.193266Z"
    },
    "id": "fqMOuDutnOxK"
   },
   "outputs": [],
   "source": [
    "# one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9yDoa0G3IgQ"
   },
   "source": [
    "Run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:14.197481Z",
     "iopub.status.busy": "2022-05-03T11:16:14.197261Z",
     "iopub.status.idle": "2022-05-03T11:16:16.999406Z",
     "shell.execute_reply": "2022-05-03T11:16:16.998550Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# states = None\n",
    "# next_char = tf.constant(['ROMEO:'])\n",
    "# result = [next_char]\n",
    "\n",
    "# for n in range(1000):\n",
    "#   next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "#   result.append(next_char)\n",
    "\n",
    "# result = tf.strings.join(result)\n",
    "# end = time.time()\n",
    "# print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "# print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "The easiest thing you can do to improve the results is to train it for longer (try `EPOCHS = 30`).\n",
    "\n",
    "You can also experiment with a different start string, try adding another RNN layer to improve the model's accuracy, or adjust the temperature parameter to generate more or less random predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OfbI4aULmuj"
   },
   "source": [
    "If you want the model to generate text *faster* the easiest thing you can do is batch the text generation. In the example below the model generates 5 outputs in about the same time it took to generate 1 above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:17.003638Z",
     "iopub.status.busy": "2022-05-03T11:16:17.003091Z",
     "iopub.status.idle": "2022-05-03T11:16:19.889165Z",
     "shell.execute_reply": "2022-05-03T11:16:19.888346Z"
    },
    "id": "ZkLu7Y8UCMT7"
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# states = None\n",
    "# next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "# result = [next_char]\n",
    "\n",
    "# for n in range(1000):\n",
    "#   next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "#   result.append(next_char)\n",
    "\n",
    "# result = tf.strings.join(result)\n",
    "# end = time.time()\n",
    "# print(result, '\\n\\n' + '_'*80)\n",
    "# print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUQzwu6EXam"
   },
   "source": [
    "## Export the generator\n",
    "\n",
    "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:19.892817Z",
     "iopub.status.busy": "2022-05-03T11:16:19.892356Z",
     "iopub.status.idle": "2022-05-03T11:16:25.713605Z",
     "shell.execute_reply": "2022-05-03T11:16:25.712920Z"
    },
    "id": "3Grk32H_CzsC"
   },
   "outputs": [],
   "source": [
    "# tf.saved_model.save(one_step_model, 'one_step')\n",
    "# one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:25.717639Z",
     "iopub.status.busy": "2022-05-03T11:16:25.717293Z",
     "iopub.status.idle": "2022-05-03T11:16:26.290665Z",
     "shell.execute_reply": "2022-05-03T11:16:26.289994Z"
    },
    "id": "_Z9bb_wX6Uuu"
   },
   "outputs": [],
   "source": [
    "# states = None\n",
    "# next_char = tf.constant(['ROMEO:'])\n",
    "# result = [next_char]\n",
    "\n",
    "# for n in range(100):\n",
    "#   next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "#   result.append(next_char)\n",
    "\n",
    "# print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## Advanced: Customized Training\n",
    "\n",
    "The above training procedure is simple, but does not give you much control.\n",
    "It uses teacher-forcing which prevents bad predictions from being fed back to the model, so the model never learns to recover from mistakes.\n",
    "\n",
    "So now that you've seen how to run the model manually next you'll implement the training loop. This gives a starting point if, for example, you want to implement _curriculum  learning_ to help stabilize the model's open-loop output.\n",
    "\n",
    "The most important part of a custom training loop is the train step function.\n",
    "\n",
    "Use `tf.GradientTape` to track the gradients. You can learn more about this approach by reading the [eager execution guide](https://www.tensorflow.org/guide/eager).\n",
    "\n",
    "The basic procedure is:\n",
    "\n",
    "1. Execute the model and calculate the loss under a `tf.GradientTape`.\n",
    "2. Calculate the updates and apply them to the model using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:26.294602Z",
     "iopub.status.busy": "2022-05-03T11:16:26.294061Z",
     "iopub.status.idle": "2022-05-03T11:16:26.299341Z",
     "shell.execute_reply": "2022-05-03T11:16:26.298736Z"
    },
    "id": "x0pZ101hjwW0"
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oc-eJALcK8B"
   },
   "source": [
    "The above implementation of the `train_step` method follows [Keras' `train_step` conventions](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). This is optional, but it allows you to change the behavior of the train step and still use keras' `Model.compile` and `Model.fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:26.302600Z",
     "iopub.status.busy": "2022-05-03T11:16:26.302139Z",
     "iopub.status.idle": "2022-05-03T11:16:26.311658Z",
     "shell.execute_reply": "2022-05-03T11:16:26.311061Z"
    },
    "id": "XKyWiZ_Lj7w5"
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:26.314979Z",
     "iopub.status.busy": "2022-05-03T11:16:26.314533Z",
     "iopub.status.idle": "2022-05-03T11:16:26.322155Z",
     "shell.execute_reply": "2022-05-03T11:16:26.321588Z"
    },
    "id": "U817KUm7knlm"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:16:26.325258Z",
     "iopub.status.busy": "2022-05-03T11:16:26.324824Z",
     "iopub.status.idle": "2022-05-03T11:16:33.920577Z",
     "shell.execute_reply": "2022-05-03T11:16:33.920032Z"
    },
    "id": "o694aoBPnEi9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "215/215 [==============================] - 90s 395ms/step - loss: 2.3896\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.6145\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 90s 397ms/step - loss: 1.3749\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.2765\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 89s 397ms/step - loss: 1.2235\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 89s 397ms/step - loss: 1.1896\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.1652\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.1459\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.1304\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.1172\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.1058\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.0957\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0857\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0776\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.0692\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0621\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.0546\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.0478\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0407\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 89s 397ms/step - loss: 1.0343\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0284\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0222\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0158\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 1.0098\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 1.0046\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9986\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9931\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9878\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9827\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9777\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9732\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9687\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 89s 394ms/step - loss: 0.9644\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9600\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9569\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9522\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9486\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 92s 411ms/step - loss: 0.9455\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9429\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 89s 394ms/step - loss: 0.9399\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9379\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9347\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 89s 393ms/step - loss: 0.9327\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 89s 394ms/step - loss: 0.9302\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 89s 394ms/step - loss: 0.9284\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 89s 397ms/step - loss: 0.9261\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 89s 396ms/step - loss: 0.9250\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 89s 395ms/step - loss: 0.9235\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 88s 390ms/step - loss: 0.9215\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 88s 393ms/step - loss: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215553cefd0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8nAtKHVoInR"
   },
   "source": [
    "Or if you need more control, you can write your own complete custom training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boys today the plan is simple\n",
      "sauce and my block was innovading\n",
      "monkeys I spent $5,000 Jesus\n",
      "Christmas pleasure I've eaten our\n",
      "my proffscares twice as well jackettly\n",
      "situation she will get the same thing\n",
      "you can't see your friends for the man\n",
      "who command heat it makes you look like\n",
      "you two for four right yeah for sure\n",
      "I'm yound eyes balling it should not\n",
      "clock it 2018 likes to\n",
      "whatever you are agt so it's balage\n",
      "every chart watch the Content swipe d\n",
      "I was like wait a minute\n",
      "in bucks it kind of, fits I think we ate\n",
      "the milosional tonight for once I have\n",
      "leftovers what a good thing and so now I\n",
      "flop both of us look all right let's buy\n",
      "tax evasion say what the [ __ ]\n",
      "it is\n",
      "is this dream look anime style boy\n",
      "banning the idea better what are they\n",
      "look far feel in the goddamn russian oh\n",
      "they're [ __ ] jake it's your guts it\n",
      "just it's not for washing ninja your\n",
      "turn it's a piece of [ __ ] are you\n",
      "kidding me\n",
      "oh stick you [ __ ] oh my god it's so\n",
      "ad something depending too far\n",
      "what are you on MIPS it's a tick-tock\n",
      "from meme they called me in dude $300\n",
      "harms boy has had Luizing now oh\n",
      "[Music]\n",
      "look like you don't make it a little\n",
      "spider-man starter Pokemon yeah I know\n",
      "they have a [ __ ] Selebrate novef Olide\n",
      "VIP tavers right now for even though i\n",
      "mean like\n",
      "no guy has a bright purchase for a whole\n",
      "little doubt it seems like these\n",
      "wait for it time for some [ __ ] hars\n",
      "now yeah but this is like the only one\n",
      "back okay your taxes shoot it for your King\n",
      "for short tough tough situading as you\n",
      "carried it too he had done we'll take\n",
      "about 20 of gas pound powerful peace we need\n",
      "10 all right 145 hits the bonus for the\n",
      "person on the [ __ ] butthole Wow\n",
      "Pokemon is that that it's like they pop a\n",
      "Whole little children like a grass chat\n",
      "oh okay the teeth had she just doesn't\n",
      "exist but I'll let it have a thumbnail\n",
      "right what the Scraw guy slow here\n",
      "can we accept that even If its losest\n",
      "is still the biggest shouldn't find it\n",
      "in rabbit wow look at this pushing the\n",
      "mango whistle it will neff a lot of\n",
      "waking at my age ah [ __ ] me all I'm a\n",
      "different sky high maybe Ludwig being\n",
      "paid big tongue hmm cycling 0-1-2\n",
      "- YouTube\n",
      "i don't have japanese's amazing huh\n",
      "how are you guys doing\n",
      "now you're like a really bright side a\n",
      "nice thunk my eyes\n",
      "okay let's look he worked salad very\n",
      "strong [ __ ]\n",
      "god damn\n",
      "there's the 15\n",
      "holy [ __ ] don't do it wait wait wait\n",
      "i thought it was what happened this is\n",
      "the hardest question left with a bunch\n",
      "of winning the 9atlan\n",
      "it's gone rather than having beneful\n",
      "to point story and where would even buy\n",
      "[Music]\n",
      "collows\n",
      "with all of them i gotta be close\n",
      "through the wild news set stuff on them\n",
      "the opposite i think we need to do a\n",
      "drake\n",
      "tap as much as i\n",
      "do boys while i was better than my stream\n",
      "why\n",
      "is that right after that anything stay\n",
      "titled\n",
      "okay don't be wideki degree\n",
      "did you just do jump king\n",
      "and then i just won puff and praying\n",
      "you spawn\n",
      "but it's so\n",
      "other game okay here's what yo you\n",
      "though i was in fact we'll see what he\n",
      "looks like iron\n",
      "let's see what's happened to about 4\n",
      "000\n",
      "and everyone just give me more type you\n",
      "think he met\n",
      "dilogo dream i see it i did give it a\n",
      "girlfriend\n",
      "turns out where the chocolate\n",
      "the hell is this all right you know\n",
      "when you shaved over the pal me\n",
      "easy this game it's just gonna be like\n",
      "i guess we'll jump in the mod i just\n",
      "need so many minds oh don't look already\n",
      "i set\n",
      "he wasn't ludwig vert squish i'm not\n",
      "hell yeah it looks like those drops on\n",
      "the left she look more more complicated\n",
      "almost\n",
      "increasing i also have a beeflew ah\n",
      "[ __ ] cereal today and then i clicked\n",
      "to draw\n",
      "one good line it's a little bit further\n",
      "in results in awardshones\n",
      "sort of expected nobody will do an\n",
      "intention so that mach i don't know a\n",
      "sneak front paper\n",
      "at some point in fifth grader 200 holes\n",
      "me maybe i thought it was about\n",
      "take a youtube video for me and a sed\n",
      "and death\n",
      "it's like not a great extra bonus point\n",
      "but the thing about it\n",
      "all right that was like this phrase\n",
      "while like the thing that everyone\n",
      "calls them around\n",
      "justin maker the subs because the first\n",
      "one in society\n",
      "is for the uh video game from amaranth\n",
      "65 to 64 asis and sweeting the rest of\n",
      "the mic issues everyone on twitch hey\n",
      "really just five years you did\n",
      "oh for sure for sure\n",
      "[Music]\n",
      "um just a little bomb just let me tell\n",
      "you if it's the best ad k\n",
      "of steel because i didn't even finish\n",
      "your gun\n",
      "all right come on it's in the dead\n",
      "[ __ ] firewight how does this happen\n",
      "it's like it's fake sounds good so zayn\n",
      "are we gonna be good in a limited anal\n",
      "15.\n",
      "yeah i must be in la yeah i bet if you\n",
      "have a good answer\n",
      "grasition keyboard on your side comeback\n",
      "ten i got nothing i think it's close\n",
      "only\n",
      "i don't know they i don't think it's\n",
      "just\n",
      "don't force here was stacked\n",
      "did you believe this no smooth\n",
      "for the mighty doctors\n",
      "[Music]\n",
      "crit friends\n",
      "did you appreciation and that's up\n",
      "because\n",
      "look i tell you now let's go diversity\n",
      "but i'm navo i'm not go\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant([\"Boys today the plan is simple\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(5000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x00000213FC6EAB20>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x00000213FC6EAB20>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step_custom\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step_custom\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step_custom')\n",
    "one_step_reloaded = tf.saved_model.load('one_step_custom')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7706b380f9824b472298316d9e5ab3528d309dfb8d29195b4cfbb877367ee8c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
